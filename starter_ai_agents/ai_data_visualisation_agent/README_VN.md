# üìä AI Data Visualization Agent

·ª®ng d·ª•ng Streamlit n√†y l√† m·ªôt AI Data Visualization Agent ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi AI, ho·∫°t ƒë·ªông nh∆∞ chuy√™n gia tr·ª±c quan h√≥a d·ªØ li·ªáu c√° nh√¢n c·ªßa b·∫°n. Ch·ªâ c·∫ßn t·∫£i l√™n dataset v√† ƒë·∫∑t c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n - AI agent s·∫Ω ph√¢n t√≠ch d·ªØ li·ªáu, t·∫°o ra c√°c bi·ªÉu ƒë·ªì ph√π h·ª£p v√† cung c·∫•p insights th√¥ng qua s·ª± k·∫øt h·ª£p c·ªßa bi·ªÉu ƒë·ªì, th·ªëng k√™ v√† gi·∫£i th√≠ch.

## üéØ Ki·∫øn Th·ª©c ƒê√£ H·ªçc ƒê∆∞·ª£c

### **1. Ki·∫øn Th·ª©c T·ªïng Qu√°t**

#### **A. AI-Powered Data Analysis Pattern**

- **Kh√°i ni·ªám**: S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu v√† t·∫°o visualizations t·ª± ƒë·ªông
- **L·ª£i √≠ch**: T·ª± ƒë·ªông h√≥a qu√° tr√¨nh ph√¢n t√≠ch, gi·∫£m th·ªùi gian x·ª≠ l√Ω, insights th√¥ng minh
- **Pattern**: `Data Upload ‚Üí Natural Language Query ‚Üí AI Analysis ‚Üí Code Generation ‚Üí Visualization`

#### **B. Code Interpreter Integration**

- **V·∫•n ƒë·ªÅ**: C·∫ßn m√¥i tr∆∞·ªùng an to√†n ƒë·ªÉ th·ª±c thi code Python
- **Gi·∫£i ph√°p**: E2B Sandbox - m√¥i tr∆∞·ªùng sandbox ƒë√°m m√¢y
- **L·ª£i √≠ch**: B·∫£o m·∫≠t, scalability, kh√¥ng c·∫ßn setup local environment

#### **C. Multi-Model AI Support**

- **Meta-Llama 3.1 405B**: Cho ph√¢n t√≠ch ph·ª©c t·∫°p
- **DeepSeek V3**: Cho insights chi ti·∫øt
- **Qwen 2.5 7B**: Cho ph√¢n t√≠ch nhanh
- **Meta-Llama 3.3 70B**: Cho queries n√¢ng cao

#### **D. Natural Language to Code (NL2Code)**

- **Kh√°i ni·ªám**: Chuy·ªÉn ƒë·ªïi c√¢u h·ªèi t·ª± nhi√™n th√†nh Python code
- **·ª®ng d·ª•ng**: T·ª± ƒë·ªông t·∫°o visualizations, statistical analysis
- **Pattern**: `User Query ‚Üí LLM ‚Üí Python Code ‚Üí Execution ‚Üí Results`

### **2. V√≠ D·ª• T·ª´ Code**

#### **A. Code Interpreter Integration**

```python
# E2B Sandbox setup
with Sandbox(api_key=st.session_state.e2b_api_key) as code_interpreter:
    # Upload dataset
    dataset_path = upload_dataset(code_interpreter, uploaded_file)

    # Execute AI-generated code
    code_results, llm_response = chat_with_llm(code_interpreter, query, dataset_path)
```

#### **B. Natural Language Processing**

```python
def chat_with_llm(e2b_code_interpreter: Sandbox, user_message: str, dataset_path: str):
    system_prompt = f"""You're a Python data scientist and data visualization expert.
    You are given a dataset at path '{dataset_path}' and also the user's query.
    You need to analyze the dataset and answer the user's query with a response
    and you run Python code to solve them.
    IMPORTANT: Always use the dataset path variable '{dataset_path}' in your code
    when reading the CSV file."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message},
    ]

    # Get AI response with code
    response = client.chat.completions.create(
        model=st.session_state.model_name,
        messages=messages,
    )
```

#### **C. Code Extraction & Execution**

````python
def match_code_blocks(llm_response: str) -> str:
    pattern = re.compile(r"```python\n(.*?)\n```", re.DOTALL)
    match = pattern.search(llm_response)
    if match:
        code = match.group(1)
        return code
    return ""

def code_interpret(e2b_code_interpreter: Sandbox, code: str):
    with st.spinner('Executing code in E2B sandbox...'):
        exec = e2b_code_interpreter.run_code(code)

        if exec.error:
            print(f"[Code Interpreter ERROR] {exec.error}")
            return None
        return exec.results
````

#### **D. Multi-Model Selection**

```python
# Model selection dropdown
model_options = {
    "Meta-Llama 3.1 405B": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "DeepSeek V3": "deepseek-ai/DeepSeek-V3",
    "Qwen 2.5 7B": "Qwen/Qwen2.5-7B-Instruct-Turbo",
    "Meta-Llama 3.3 70B": "meta-llama/Llama-3.3-70B-Instruct-Turbo"
}

st.session_state.model_name = st.selectbox(
    "Select Model",
    options=list(model_options.keys()),
    index=0
)
```

#### **E. Result Visualization**

```python
# Display different types of results
if code_results:
    for result in code_results:
        if hasattr(result, 'png') and result.png:
            # Decode base64 PNG data
            png_data = base64.b64decode(result.png)
            image = Image.open(BytesIO(png_data))
            st.image(image, caption="Generated Visualization")
        elif hasattr(result, 'figure'):
            # Matplotlib figures
            fig = result.figure
            st.pyplot(fig)
        elif hasattr(result, 'show'):
            # Plotly figures
            st.plotly_chart(result)
        elif isinstance(result, (pd.DataFrame, pd.Series)):
            # DataFrames
            st.dataframe(result)
        else:
            st.write(result)
```

### **3. T·ªïng H·ª£p C√°ch S·ª≠ D·ª•ng Cho Sau N√†y**

#### **A. Template AI Data Analysis System**

```python
# Template c∆° b·∫£n cho AI data analysis system
def create_ai_data_analysis_system():
    # 1. Setup code interpreter
    with Sandbox(api_key=e2b_api_key) as code_interpreter:
        # 2. Upload dataset
        dataset_path = upload_dataset(code_interpreter, uploaded_file)

        # 3. Process user query
        code_results, llm_response = chat_with_llm(
            code_interpreter,
            user_query,
            dataset_path
        )

        # 4. Display results
        display_results(code_results, llm_response)
```

#### **B. Code Interpreter Best Practices**

```python
# Best practices for code interpreter
def robust_code_execution():
    # ‚úÖ 1. Error handling
    try:
        exec = code_interpreter.run_code(code)
        if exec.error:
            st.error(f"Code execution error: {exec.error}")
            return None
    except Exception as e:
        st.error(f"Unexpected error: {e}")
        return None

    # ‚úÖ 2. Output capture
    with contextlib.redirect_stdout(stdout_capture):
        with contextlib.redirect_stderr(stderr_capture):
            exec = code_interpreter.run_code(code)

    # ‚úÖ 3. Result processing
    if exec.results:
        for result in exec.results:
            process_result(result)
```

#### **C. Multi-Model Strategy**

```python
# Model selection strategy
def select_appropriate_model(task_type):
    model_mapping = {
        "simple_analysis": "Qwen/Qwen2.5-7B-Instruct-Turbo",
        "complex_analysis": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "detailed_insights": "deepseek-ai/DeepSeek-V3",
        "advanced_queries": "meta-llama/Llama-3.3-70B-Instruct-Turbo"
    }
    return model_mapping.get(task_type, "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo")
```

#### **D. Natural Language to Code Template**

```python
# NL2Code template
def create_nl2code_system():
    system_prompt = """You're a Python data scientist and visualization expert.
    Given a dataset and user query, generate Python code to:
    1. Load and analyze the data
    2. Create appropriate visualizations
    3. Provide statistical insights
    4. Answer the user's question

    Always use the provided dataset path and ensure code is executable."""

    def process_query(user_query, dataset_path):
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Dataset: {dataset_path}\nQuery: {user_query}"}
        ]

        response = llm_client.chat.completions.create(
            model=selected_model,
            messages=messages
        )

        # Extract and execute code
        code = extract_code_blocks(response.choices[0].message.content)
        results = execute_code(code)

        return results, response.choices[0].message.content
```

#### **E. Result Processing Template**

```python
# Result processing template
def process_visualization_results(results):
    for result in results:
        if hasattr(result, 'png'):
            # Handle PNG images
            display_image(result.png)
        elif hasattr(result, 'figure'):
            # Handle matplotlib figures
            display_matplotlib_figure(result.figure)
        elif hasattr(result, 'show'):
            # Handle plotly figures
            display_plotly_chart(result)
        elif isinstance(result, pd.DataFrame):
            # Handle DataFrames
            display_dataframe(result)
        else:
            # Handle other results
            display_text_result(result)
```

### **4. Best Practices Summary**

```python
# Best practices checklist
def apply_data_visualization_best_practices():
    # ‚úÖ 1. Code interpreter integration
    # - Use secure sandbox environment
    # - Handle errors gracefully
    # - Capture all outputs

    # ‚úÖ 2. Multi-model support
    # - Select appropriate model for task
    # - Provide model selection UI
    # - Handle model-specific features

    # ‚úÖ 3. Natural language processing
    # - Clear system prompts
    # - Context-aware responses
    # - Code extraction reliability

    # ‚úÖ 4. Result visualization
    # - Support multiple output types
    # - Handle different visualization libraries
    # - Provide fallback options

    # ‚úÖ 5. User experience
    # - Progress indicators
    # - Error messages
    # - Interactive model selection

    # ‚úÖ 6. Security
    # - Sandboxed code execution
    # - Input validation
    # - Safe file handling
```

## üéØ H∆∞·ªõng d·∫´n Prompt Engineering

### Ki·∫øn th·ª©c t·ªïng qu√°t

#### **1. System Prompt Design**

- **Role Definition**: "You're a Python data scientist and visualization expert"
- **Context Injection**: Provide dataset path and user query
- **Task Specification**: Clear instructions for code generation
- **Quality Constraints**: Ensure executable, well-formatted code

#### **2. Code Generation Patterns**

```python
# Effective system prompt structure
system_prompt = f"""You're a Python data scientist and data visualization expert.
You are given a dataset at path '{dataset_path}' and also the user's query.

You need to analyze the dataset and answer the user's query with a response
and you run Python code to solve them.

IMPORTANT: Always use the dataset path variable '{dataset_path}' in your code
when reading the CSV file.

Guidelines:
1. Load the dataset using pandas
2. Perform necessary data analysis
3. Create appropriate visualizations
4. Provide statistical insights
5. Answer the user's specific question
6. Ensure all code is executable and well-formatted"""
```

#### **3. Code Extraction Techniques**

````python
# Robust code extraction
def extract_code_blocks(response_text):
    # Multiple patterns for different code block formats
    patterns = [
        r"```python\n(.*?)\n```",
        r"```\n(.*?)\n```",
        r"```py\n(.*?)\n```"
    ]

    for pattern in patterns:
        match = re.search(pattern, response_text, re.DOTALL)
        if match:
            return match.group(1).strip()

    return ""
````

#### **4. Error Handling in Code Generation**

```python
# Error handling for AI-generated code
def safe_code_execution(code, code_interpreter):
    try:
        # Validate code before execution
        if not code.strip():
            return None, "No code generated"

        # Execute in sandbox
        exec_result = code_interpreter.run_code(code)

        if exec_result.error:
            return None, f"Execution error: {exec_result.error}"

        return exec_result.results, None

    except Exception as e:
        return None, f"Unexpected error: {str(e)}"
```

## T√≠nh nƒÉng

#### **Ph√¢n T√≠ch D·ªØ Li·ªáu B·∫±ng Ng√¥n Ng·ªØ T·ª± Nhi√™n**

- ƒê·∫∑t c√¢u h·ªèi v·ªÅ d·ªØ li·ªáu b·∫±ng ti·∫øng Anh ƒë∆°n gi·∫£n
- Nh·∫≠n visualizations v√† ph√¢n t√≠ch th·ªëng k√™ t·ª©c th√¨
- Nh·∫≠n gi·∫£i th√≠ch v·ªÅ findings v√† insights
- H·ªèi ƒë√°p t∆∞∆°ng t√°c theo d√µi

#### **L·ª±a Ch·ªçn Visualization Th√¥ng Minh**

- T·ª± ƒë·ªông ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì ph√π h·ª£p
- T·∫°o visualization ƒë·ªông
- H·ªó tr·ª£ visualization th·ªëng k√™
- ƒê·ªãnh d·∫°ng v√† styling bi·ªÉu ƒë·ªì t√πy ch·ªânh

#### **H·ªó Tr·ª£ AI ƒêa Model**

- Meta-Llama 3.1 405B cho ph√¢n t√≠ch ph·ª©c t·∫°p
- DeepSeek V3 cho insights chi ti·∫øt
- Qwen 2.5 7B cho ph√¢n t√≠ch nhanh
- Meta-Llama 3.3 70B cho queries n√¢ng cao

## C√°ch b·∫Øt ƒë·∫ßu?

1. **Clone kho l∆∞u tr·ªØ GitHub**

```bash
git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git
cd awesome-llm-apps/starter_ai_agents/ai_data_visualisation_agent
```

2. **C√†i ƒë·∫∑t c√°c dependencies c·∫ßn thi·∫øt:**

```bash
pip install -r requirements.txt
```

3. **L·∫•y Together AI API Key**

- ƒêƒÉng k√Ω t√†i kho·∫£n [Together AI](https://api.together.ai/signin) v√† l·∫•y API key c·ªßa b·∫°n.
- M·ªçi ng∆∞·ªùi ƒë·ªÅu nh·∫≠n ƒë∆∞·ª£c $1 credit mi·ªÖn ph√≠ t·ª´ Together AI - AI Acceleration Cloud platform

4. **L·∫•y E2B API Key**

- ƒêƒÉng k√Ω t√†i kho·∫£n [E2B](https://e2b.dev/) v√† l·∫•y API key c·ªßa b·∫°n.
- Xem h∆∞·ªõng d·∫´n: [E2B Getting Started](https://e2b.dev/docs/legacy/getting-started/api-key)

5. **Ch·∫°y ·ª©ng d·ª•ng Streamlit**

```bash
streamlit run ai_data_visualisation_agent.py
```

## C√°ch ho·∫°t ƒë·ªông?

AI Data Visualization Agent c√≥ c√°c th√†nh ph·∫ßn ch√≠nh:

1. **Data Upload**: T·∫£i l√™n file CSV v√† hi·ªÉn th·ªã preview
2. **Natural Language Query**: Ng∆∞·ªùi d√πng ƒë·∫∑t c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n
3. **AI Analysis**: LLM ph√¢n t√≠ch c√¢u h·ªèi v√† t·∫°o Python code
4. **Code Execution**: Code ƒë∆∞·ª£c th·ª±c thi trong E2B sandbox
5. **Result Display**: Hi·ªÉn th·ªã visualizations, charts v√† insights

## Workflow chi ti·∫øt

```
User Upload CSV ‚Üí Preview Data ‚Üí Enter Query ‚Üí AI Generates Code ‚Üí
Execute in Sandbox ‚Üí Display Results (Charts/Stats/Insights)
```

## S·ª≠ d·ª•ng t√≠nh nƒÉng

1. **T·∫£i l√™n dataset**: Ch·ªçn file CSV t·ª´ m√°y t√≠nh
2. **Xem preview**: Ki·ªÉm tra d·ªØ li·ªáu tr∆∞·ªõc khi ph√¢n t√≠ch
3. **ƒê·∫∑t c√¢u h·ªèi**: S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n ƒë·ªÉ h·ªèi v·ªÅ d·ªØ li·ªáu
4. **Ch·ªçn model**: L·ª±a ch·ªçn AI model ph√π h·ª£p v·ªõi task
5. **Ph√¢n t√≠ch**: Nh·∫•n "Analyze" ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh
6. **Xem k·∫øt qu·∫£**: Nh·∫≠n visualizations, charts v√† insights

## V√≠ d·ª• c√¢u h·ªèi

- "Can you compare the average cost for two people between different categories?"
- "Show me the distribution of ratings"
- "What are the top 10 most expensive items?"
- "Create a correlation matrix for numerical columns"
- "Show trends over time if there's a date column"

## L∆∞u √Ω quan tr·ªçng

- **API Keys**: C·∫ßn c·∫£ Together AI v√† E2B API keys
- **File Format**: Ch·ªâ h·ªó tr·ª£ file CSV
- **Code Execution**: T·∫•t c·∫£ code ƒë∆∞·ª£c th·ª±c thi trong sandbox an to√†n
- **Model Selection**: Ch·ªçn model ph√π h·ª£p v·ªõi ƒë·ªô ph·ª©c t·∫°p c·ªßa task
- **Error Handling**: App s·∫Ω hi·ªÉn th·ªã l·ªói n·∫øu c√≥ v·∫•n ƒë·ªÅ v·ªõi code generation ho·∫∑c execution
